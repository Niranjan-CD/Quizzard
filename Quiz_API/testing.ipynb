{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# from flask_cors import CORS\n",
    "import requests\n",
    "import os\n",
    "from newsplease import NewsPlease\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.6, max_tokens=4096)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "basepath = os.path.abspath(os.curdir)\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "output_parser = StrOutputParser()\n",
    "load_dotenv()\n",
    "\n",
    "# Imports End here\n",
    "\n",
    "basepath = os.path.abspath(os.curdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_prompt(chain_name,basepath=basepath):\n",
    "    with open(basepath+'\\\\prompts\\\\'+chain_name+'-prompt.txt',encoding='utf-8') as fh:\n",
    "        return fh.read()\n",
    "\n",
    "def create_chain(chain_name,sample):\n",
    "    if sample==False:\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"system\", read_prompt(chain_name)),(\"user\", \"{input}\")])\n",
    "        final_chain =  prompt | llm | output_parser    \n",
    "        return final_chain\n",
    "    elif sample==True:\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"system\", read_prompt(chain_name)),(\"user\", \"{input}\")])\n",
    "        if  chain_name[:4] == 'logi':\n",
    "            loader = UnstructuredExcelLoader(basepath+'\\\\Training\\\\'+chain_name+\"-train.xlsx\")\n",
    "        elif  chain_name[:4] == 'stat':\n",
    "            loader = TextLoader(basepath+'\\\\Training\\\\'+chain_name+\"-train.txt\")\n",
    "        elif  chain_name[:4] == 'fact':\n",
    "            loader = TextLoader(basepath+'\\\\Training\\\\'+chain_name+\"-train.txt\")\n",
    "        data = loader.load()\n",
    "        documents = text_splitter.split_documents(data)\n",
    "        vector = FAISS.from_documents(documents, embeddings)\n",
    "        document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "        retriever = vector.as_retriever()\n",
    "        return create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "\n",
    "def init_all_chains():\n",
    "    chains = {}\n",
    "    chain_names = [x[:8] for x in os.listdir(basepath+'\\\\'+'prompts')]\n",
    "    for chain_name in chain_names:\n",
    "        if chain_name in ['logi-con','logi-par']:\n",
    "            chains[chain_name] = create_chain(chain_name,sample=False)\n",
    "            print(chain_name,' Success without context')\n",
    "            continue\n",
    "        chains[chain_name] = create_chain(chain_name,sample=True)\n",
    "        print(chain_name,' Success with context')\n",
    "           \n",
    "    print('completed initializing all chains')\n",
    "    return chains\n",
    "\n",
    "\n",
    "\n",
    "chains = init_all_chains()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Codes\n",
    "def get_articles(urls):\n",
    "    '''Method to scrape articles using URLs'''\n",
    "    articles = []\n",
    "    for url in urls:\n",
    "        if not requests.get(url).ok:\n",
    "            print(\"Cannot scrape URL \"+str((urls.index(url))+1)+\" due to copyright issues.\")\n",
    "            continue\n",
    "        raw_article = NewsPlease.from_url(url,timeout=5)\n",
    "        if raw_article.maintext==None:\n",
    "            print(\"Cannot scrape URL \"+str((urls.index(url))+1)+\" due to copyright issues.\")\n",
    "            continue\n",
    "        articles.append(raw_article.maintext)\n",
    "    print(\"\\nScraped \"+str(len(articles))+\" out of \"+str(len(urls))+\" URLs.\\n\\nProcessing scraped articles...\")\n",
    "    return articles\n",
    "def invoke(chain,input,chains=chains):\n",
    "    response =  chains[chain].invoke({\"input\": input})\n",
    "    print(chain,\" ran successfully\")\n",
    "    return response['answer']\n",
    "def invoke_no_sample(chain,input,chains=chains):\n",
    "    response =  chains[chain].invoke({\"input\": input})\n",
    "    print(chain,\" ran successfully\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Logical chain codes\n",
    "\n",
    "\n",
    "\n",
    "def check_validity(response):\n",
    "    validity = response.split('\\n\\n')[-1]\n",
    "    if (\"invalid\" or \"not valid\") in validity.lower():\n",
    "        decision = False\n",
    "    elif \"valid\" in validity.lower():\n",
    "        decision = True\n",
    "    else:\n",
    "        decision = False\n",
    "    return decision\n",
    "\n",
    "\n",
    "def process_final(final_mcq):\n",
    "    f = False\n",
    "    res = ''\n",
    "    fin = ''\n",
    "    temp_split =final_mcq.split('\\n\\n') \n",
    "    for mrl in temp_split:\n",
    "        if mrl[:10].lower()==\"output mcq\":\n",
    "            res = mrl[12:]\n",
    "            # if fin.splitlines()[-1][:7] != 'correct':\n",
    "            #     temp_split.index(mrl)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "'https://www.edie.net/carbon-majors-worlds-biggest-emitters-grew-their-carbon-footprint-since-paris-agreement-study-finds/',\n",
    "'https://www.earth.com/news/using-ai-writing-illustration-drastically-reduces-carbon-footprint/'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_articles(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_articles(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_articles_logi(articles):\n",
    "    # print(articles[0])\n",
    "    # print(articles[1])\n",
    "    valid_paragraphs = []\n",
    "    rel = []\n",
    "    par = []\n",
    "    for article in articles:  \n",
    "        relevant_text = invoke_no_sample('logi-con', article)\n",
    "        rel.append(relevant_text)\n",
    "        paraphrased_text = invoke_no_sample('logi-par',relevant_text)\n",
    "        par.append(paraphrased_text)\n",
    "        paragraph_list = [pl for pl in paraphrased_text.split(\"\\n\\n\") if len(pl)>100]\n",
    "        val_responses = []\n",
    "        for paragraph in paragraph_list:\n",
    "            val_response = invoke('logi-val',paragraph)\n",
    "            val_responses.append(val_response)\n",
    "            val_response_list = val_response.split(\"\\n\\n\")\n",
    "            validity = val_response_list[2]\n",
    "            if (\"invalid\" or \"not valid\") in validity.lower():\n",
    "                decision = \"Invalid\"\n",
    "            elif \"valid\" in validity.lower():\n",
    "                decision = \"Valid\"\n",
    "            else:\n",
    "                decision = \"Unclear\"\n",
    "            if decision == \"Valid\":\n",
    "                valid_paragraphs.append(paragraph)\n",
    "    return valid_paragraphs,rel,par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_paragraphs,rel,par = preprocess_articles_logi(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_chain(valid_paragraphs):\n",
    "    ques_responses = []\n",
    "    opt_responses = []\n",
    "    pre_improve = []\n",
    "    improved_responses = []\n",
    "    final_mcqs = []\n",
    "    for p in valid_paragraphs:\n",
    "        #Question\n",
    "        ques_response = invoke('logi-que', p)\n",
    "        ques_responses.append(ques_response)\n",
    "        ques_response_split = ques_response.split(\"\\n\\n\")\n",
    "        for qrs in ques_response_split:\n",
    "            if qrs[:6].lower()!=\"source\" and qrs[:8].lower()!=\"question\":\n",
    "                ques_response_split.remove(qrs)\n",
    "        source_text = ques_response_split[0]\n",
    "        final_ques = \"\\n\\n\".join(ques_response_split)\n",
    "        #Options\n",
    "        opt_response = invoke('logi-opt',final_ques)\n",
    "        opt_responses.append(opt_response)\n",
    "        opt_response_split = opt_response.split(\"\\n\\n\")\n",
    "        if opt_response_split[0][:6].lower()==\"source\":\n",
    "            final_opt = opt_response_split[0] + \"\\n\\n\" + opt_response_split[2]\n",
    "        else:\n",
    "            final_opt = source_text + \"\\n\\n\" + opt_response_split[1]\n",
    "        pre_improve.append(final_opt)\n",
    "        #Improvement\n",
    "        mcq_response = invoke('logi-imp', final_opt)\n",
    "        improved_responses.append(mcq_response)\n",
    "        mcq_response_list = mcq_response.split(\"\\n\\n\")\n",
    "        for mrl in mcq_response_list:\n",
    "            if mrl[:10].lower()==\"output mcq\":\n",
    "                final_mcq = mrl[12:]\n",
    "                final_mcqs.append(final_mcq)\n",
    "    return final_mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultant = logical_chain(valid_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_resultant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
